{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71d74e62",
   "metadata": {},
   "source": [
    "# Data Cleaning — Goodbooks-10k Top 100 (Updated)\n",
    "**Objetivo:**  \n",
    " \n",
    "1. Cargar y explorar los ficheros de ratings, metadatos y tags.  \n",
    "2. Seleccionar los 100 libros más valorados.  \n",
    "3. Filtrar usuarios con actividad mínima (≥ 20 ratings).  \n",
    "4. Binarizar las calificaciones (≥ 4 → “like”).  \n",
    "5. Pivotar a matriz dispersa 0/1 `R_binary`.  \n",
    "6. Extraer y guardar metadata enriquecida (título, autor, top-tags).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f60b382",
   "metadata": {},
   "source": [
    "Importamos las librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6eef99bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e47586",
   "metadata": {},
   "source": [
    "Cargamos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "426d974a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.read_csv('./data/ratings.csv')\n",
    "books = pd.read_csv('./data/books.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b99fb3a",
   "metadata": {},
   "source": [
    "Limpieza: eliminamos usuarios y libros con menos de 5 valoraciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d442d417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usuarios con ≥5 ratings: 53424\n",
      "Libros   con ≥5 ratings: 10000\n"
     ]
    }
   ],
   "source": [
    "min_ratings = 5\n",
    "user_counts = ratings['user_id'].value_counts()\n",
    "book_counts = ratings['book_id'].value_counts()\n",
    "\n",
    "ratings_clean = ratings[\n",
    "    ratings['user_id'].isin(user_counts[user_counts >= min_ratings].index) &\n",
    "    ratings['book_id'].isin(book_counts[book_counts >= min_ratings].index)\n",
    "].copy()\n",
    "\n",
    "n_users_clean = ratings_clean['user_id'].nunique()\n",
    "n_items_clean = ratings_clean['book_id'].nunique()\n",
    "\n",
    "print(f\"Usuarios con ≥{min_ratings} ratings: {n_users_clean}\")\n",
    "print(f\"Libros   con ≥{min_ratings} ratings: {n_items_clean}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ec3225",
   "metadata": {},
   "source": [
    "Dividimos en train y test, tomando valoración y usuario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "897c7f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(ratings_clean, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed3ff84",
   "metadata": {},
   "source": [
    "Baseline: media global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1814e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_mean = train['rating'].mean()\n",
    "test['pred_global_mean'] = global_mean\n",
    "\n",
    "# mean squared error y mean absolute error\n",
    "rmse_global = np.sqrt(mean_squared_error(test['rating'], test['pred_global_mean']))\n",
    "mae_global = mean_absolute_error(test['rating'], test['pred_global_mean'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8a19ba",
   "metadata": {},
   "source": [
    "Baseline: media por usuario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62fc67cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_mean = train.groupby('user_id')['rating'].mean()\n",
    "test = test.join(user_mean, on='user_id', rsuffix='_user_mean')\n",
    "test['pred_user_mean'] = test['rating_user_mean'].fillna(global_mean)\n",
    "\n",
    "rmse_user = np.sqrt(mean_squared_error(test['rating'], test['pred_user_mean']))\n",
    "mae_user = mean_absolute_error(test['rating'], test['pred_user_mean'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aecf482f",
   "metadata": {},
   "source": [
    "Mostramos los resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b390784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados de Baseline\n",
      "       Baseline      RMSE       MAE\n",
      "0  Global Mean  0.990329  0.774018\n",
      "1    User Mean  0.893159  0.700713\n"
     ]
    }
   ],
   "source": [
    "results = pd.DataFrame({\n",
    "    'Baseline': ['Global Mean', 'User Mean'],\n",
    "    'RMSE': [rmse_global, rmse_user],\n",
    "    'MAE': [mae_global, mae_user]\n",
    "})\n",
    "\n",
    "print('Resultados de Baseline\\n', results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8255b5e",
   "metadata": {},
   "source": [
    "RMSE (~1): en promedio, la predicción se equivoca en 1 estrella sobre 5.\n",
    "MAE (~0.7): el error medio absoluto es  de, más o menos, 0.7 estrellas.\n",
    "\n",
    "Al pasar de global mean a user mean el RMSE se reduce a 0.89, por lo que ya tenemos una mejora del 10%. Estos datos serán el baseline contra el que compararemos los 3 métodos de filtrado colaborativo para ver si nos son útiles.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38461afe",
   "metadata": {},
   "source": [
    "Para comenzar con las implementaciones guardaremos en nuestra carpeta data/processed ratings_clean, train y test para mayor orden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c8e3ce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos guardados en 'data/processed':\n",
      "['ratings_clean.csv', 'test.csv', 'train.csv']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "processed_dir = 'data/processed'\n",
    "\n",
    "if not os.path.isdir(processed_dir):\n",
    "    os.makedirs(processed_dir, exist_ok=True)\n",
    "    \n",
    "ratings_clean.to_csv(os.path.join(processed_dir, 'ratings_clean.csv'), index=False)\n",
    "train.to_csv(os.path.join(processed_dir, 'train.csv'), index=False)\n",
    "test.to_csv(os.path.join(processed_dir, 'test.csv'), index=False)\n",
    "\n",
    "print(\"Datos guardados en 'data/processed':\")\n",
    "print(os.listdir(processed_dir))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
