{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5078a3d3",
   "metadata": {},
   "source": [
    "### 1. Importamos librerías y cargamos los datos procesados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "805b96cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "processed_dir = 'data/processed'\n",
    "train_df = pd.read_csv(os.path.join(processed_dir, 'train.csv'))\n",
    "test_df  = pd.read_csv(os.path.join(processed_dir, 'test.csv'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef5523e",
   "metadata": {},
   "source": [
    "### 2. Declaramos nuestros hiperparámetros y constantes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24650b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_ITERATIONS = 10      # iteraciones\n",
    "MIN_RATING, MAX_RATING = 1.0, 5.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e15281",
   "metadata": {},
   "source": [
    "#### Matriz de valoraciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5cf6d6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lista de listas (0 donde no hay rating)\n",
    "num_users = int(max(train_df.user_id.max(), test_df.user_id.max()))\n",
    "num_items = int(max(train_df.book_id.max(), test_df.book_id.max()))\n",
    "R = [[0.0]*num_items for _ in range(num_users)]\n",
    "for _, row in train_df.iterrows():\n",
    "    u = int(row.user_id) - 1\n",
    "    i = int(row.book_id) - 1\n",
    "    R[u][i] = float(row.rating)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb29086b",
   "metadata": {},
   "source": [
    "### 3. Inicializamos el modelo, hiperparámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00c529e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_FACTORS    = 7       # f\n",
    "LEARNING_RATE  = 0.001   # γ\n",
    "REGULARIZATION = 0.1     # λ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3767dc5",
   "metadata": {},
   "source": [
    "### 4. Creamos P y Q con uniformes en [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d6847f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "P = [[random.random() for _ in range(NUM_FACTORS)] for _ in range(num_users)]\n",
    "Q = [[random.random() for _ in range(NUM_FACTORS)] for _ in range(num_items)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8079dd9d",
   "metadata": {},
   "source": [
    "### 5. SGD iterativo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9d328f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteración 1/10\n",
      "Iteración 2/10\n"
     ]
    }
   ],
   "source": [
    "for it in range(NUM_ITERATIONS):\n",
    "    print(f\"Iteración {it+1}/{NUM_ITERATIONS}\")\n",
    "    updated_P = [row.copy() for row in P]\n",
    "    updated_Q = [row.copy() for row in Q]\n",
    "\n",
    "    # Recorremos sólo las valoraciones reales:\n",
    "    for _, row in train_df.iterrows():\n",
    "        u = int(row.user_id) - 1\n",
    "        i = int(row.book_id) - 1\n",
    "        r_ui = float(row.rating)\n",
    "\n",
    "        # Cálculo del error\n",
    "        pred = sum(P[u][k] * Q[i][k] for k in range(NUM_FACTORS))\n",
    "        e = r_ui - pred\n",
    "\n",
    "        # Actualización por cada factor latente\n",
    "        for k in range(NUM_FACTORS):\n",
    "            p_uk = P[u][k]\n",
    "            q_ik = Q[i][k]\n",
    "            grad_p = e * q_ik - REGULARIZATION * p_uk\n",
    "            grad_q = e * p_uk - REGULARIZATION * q_ik\n",
    "            updated_P[u][k] += LEARNING_RATE * grad_p\n",
    "            updated_Q[i][k] += LEARNING_RATE * grad_q\n",
    "\n",
    "    P, Q = updated_P, updated_Q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8314f262",
   "metadata": {},
   "source": [
    "### 6. Evaluación del modelo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3271820",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     12\u001b[39m pred_matrix = np.dot(np.array(P), np.array(Q).T)\n\u001b[32m     13\u001b[39m pred_matrix = np.clip(pred_matrix, MIN_RATING, MAX_RATING) \u001b[38;5;66;03m# usamos clip para asegurar que todos los ratings queden en el intervalo que queremos\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m mae, rmse = \u001b[43mget_regression_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpred_matrix\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 6\u001b[39m, in \u001b[36mget_regression_metrics\u001b[39m\u001b[34m(test_df, pred_matrix)\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"devolvemos MAE y RMSE para todas las valoraciones de test_df\"\"\"\u001b[39;00m\n\u001b[32m      3\u001b[39m y_true = test_df[\u001b[33m'\u001b[39m\u001b[33mrating\u001b[39m\u001b[33m'\u001b[39m].values\n\u001b[32m      4\u001b[39m y_pred = \u001b[43m[\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpred_matrix\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m.\u001b[49m\u001b[43muser_id\u001b[49m\u001b[43m)\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbook_id\u001b[49m\u001b[43m)\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtest_df\u001b[49m\u001b[43m.\u001b[49m\u001b[43miterrows\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m      8\u001b[39m mae  = mean_absolute_error(y_true, y_pred)\n\u001b[32m      9\u001b[39m rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\MAM\\OneDrive - Universidad Politécnica de Madrid\\Escritorio\\Apuntes_CDIA\\recomendaciones_csp\\venv\\Lib\\site-packages\\pandas\\core\\frame.py:1554\u001b[39m, in \u001b[36mDataFrame.iterrows\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1552\u001b[39m using_cow = using_copy_on_write()\n\u001b[32m   1553\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m.index, \u001b[38;5;28mself\u001b[39m.values):\n\u001b[32m-> \u001b[39m\u001b[32m1554\u001b[39m     s = \u001b[43mklass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m.__finalize__(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m   1555\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m using_cow \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._mgr.is_single_block:\n\u001b[32m   1556\u001b[39m         s._mgr.add_references(\u001b[38;5;28mself\u001b[39m._mgr)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\MAM\\OneDrive - Universidad Politécnica de Madrid\\Escritorio\\Apuntes_CDIA\\recomendaciones_csp\\venv\\Lib\\site-packages\\pandas\\core\\series.py:588\u001b[39m, in \u001b[36mSeries.__init__\u001b[39m\u001b[34m(self, data, index, dtype, name, copy, fastpath)\u001b[39m\n\u001b[32m    586\u001b[39m manager = _get_option(\u001b[33m\"\u001b[39m\u001b[33mmode.data_manager\u001b[39m\u001b[33m\"\u001b[39m, silent=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    587\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m manager == \u001b[33m\"\u001b[39m\u001b[33mblock\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m588\u001b[39m     data = \u001b[43mSingleBlockManager\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrefs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrefs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    589\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m manager == \u001b[33m\"\u001b[39m\u001b[33marray\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    590\u001b[39m     data = SingleArrayManager.from_array(data, index)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\MAM\\OneDrive - Universidad Politécnica de Madrid\\Escritorio\\Apuntes_CDIA\\recomendaciones_csp\\venv\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1870\u001b[39m, in \u001b[36mSingleBlockManager.from_array\u001b[39m\u001b[34m(cls, array, index, refs)\u001b[39m\n\u001b[32m   1863\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m   1864\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfrom_array\u001b[39m(\n\u001b[32m   1865\u001b[39m     \u001b[38;5;28mcls\u001b[39m, array: ArrayLike, index: Index, refs: BlockValuesRefs | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1866\u001b[39m ) -> SingleBlockManager:\n\u001b[32m   1867\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1868\u001b[39m \u001b[33;03m    Constructor for if we have an array that is not yet a Block.\u001b[39;00m\n\u001b[32m   1869\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1870\u001b[39m     array = \u001b[43mmaybe_coerce_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1871\u001b[39m     bp = BlockPlacement(\u001b[38;5;28mslice\u001b[39m(\u001b[32m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(index)))\n\u001b[32m   1872\u001b[39m     block = new_block(array, placement=bp, ndim=\u001b[32m1\u001b[39m, refs=refs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\MAM\\OneDrive - Universidad Politécnica de Madrid\\Escritorio\\Apuntes_CDIA\\recomendaciones_csp\\venv\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:2645\u001b[39m, in \u001b[36mmaybe_coerce_values\u001b[39m\u001b[34m(values)\u001b[39m\n\u001b[32m   2638\u001b[39m     \u001b[34m__slots__\u001b[39m = ()\n\u001b[32m   2641\u001b[39m \u001b[38;5;66;03m# -----------------------------------------------------------------\u001b[39;00m\n\u001b[32m   2642\u001b[39m \u001b[38;5;66;03m# Constructor Helpers\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2645\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmaybe_coerce_values\u001b[39m(values: ArrayLike) -> ArrayLike:\n\u001b[32m   2646\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   2647\u001b[39m \u001b[33;03m    Input validation for values passed to __init__. Ensure that\u001b[39;00m\n\u001b[32m   2648\u001b[39m \u001b[33;03m    any datetime64/timedelta64 dtypes are in nanoseconds.  Ensure\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   2657\u001b[39m \u001b[33;03m    values : np.ndarray or ExtensionArray\u001b[39;00m\n\u001b[32m   2658\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m   2659\u001b[39m     \u001b[38;5;66;03m# Caller is responsible for ensuring NumpyExtensionArray is already extracted.\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "def get_regression_metrics(test_df, pred_matrix):\n",
    "    \"\"\"devolvemos MAE y RMSE para todas las valoraciones de test_df\"\"\"\n",
    "    y_true = test_df['rating'].values\n",
    "    y_pred = [\n",
    "        pred_matrix[int(row.user_id)-1, int(row.book_id)-1]\n",
    "        for _, row in test_df.iterrows()\n",
    "    ]\n",
    "    mae  = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    return mae, rmse\n",
    "\n",
    "pred_matrix = np.dot(np.array(P), np.array(Q).T)\n",
    "pred_matrix = np.clip(pred_matrix, MIN_RATING, MAX_RATING) # usamos clip para asegurar que todos los ratings queden en el intervalo que queremos\n",
    "\n",
    "mae, rmse = get_regression_metrics(test_df, pred_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32281e40",
   "metadata": {},
   "source": [
    "#### Métricas de clasificación binaria\n",
    "\n",
    "Tanto el **RMSE** como el **MAE** son métricas de regresión (distancia a la realidad de la predicción), mientras que el **F1-score** o el **Recall** miden la precisión con que nuestro modelo recomienda algo que, efectivamente, gusta al usuario. Para ello desarrollamos la siguiente función."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f810adc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "def get_binary_metrics(test_df, pred_matrix, threshold=4.0):\n",
    "    \"\"\"\n",
    "    Binariza la tarea en like>=threshold vs dislike<threshold.\n",
    "    Devuelve precision, recall, f1.\n",
    "    \"\"\"\n",
    "    y_true = (test_df['rating'] >= threshold).astype(int).values\n",
    "    y_pred = [\n",
    "        1 if pred_matrix[int(row.user_id)-1, int(row.book_id)-1] >= threshold else 0\n",
    "        for _, row in test_df.iterrows()\n",
    "    ]\n",
    "    prec = precision_score(y_true, y_pred, zero_division=0)\n",
    "    rec  = recall_score(y_true, y_pred, zero_division=0)\n",
    "    f1   = f1_score(y_true, y_pred, zero_division=0)\n",
    "    return prec, rec, f1\n",
    "\n",
    "prec, rec, f1 = get_binary_metrics(test_df, pred_matrix, threshold = 3.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456e427c",
   "metadata": {},
   "source": [
    "#### nDCG@K (Normalized Discounted Cumulative Gain)\n",
    "\n",
    "Para evaluar la **calidad del ranking** de nuestras recomendaciones usamos nDCG@K, que mide:\n",
    "\n",
    "1. **Relevancia**: asignamos a cada ítem una relevancia real (por ejemplo `1` si la valoración ≥4, `0` en otro caso).  \n",
    "2. **Posición**: los ítems recomendados en los primeros puestos pesan más que los de atrás, mediante un descuento logarítmico.\n",
    "\n",
    "- **1.0** indica ranking perfecto (los K ítems más relevantes están en las primeras posiciones).  \n",
    "- **0.0** indica que ninguno de los K primeros es relevante.\n",
    "\n",
    "En nuestro experimento usamos **nDCG@10** para comparar KNN, PMF y SVD, asegurando no solo que predecimos bien los ratings (RMSE/MAE), sino también que colocamos primero las recomendaciones que el usuario considera más valiosas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab65c43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_ndcg(u, pred_matrix, test_df, K=5, rel_col='rel'):\n",
    "    \"\"\"\n",
    "    nDCG@K para el usuario u (0-based).\n",
    "    test_df debe tener columnas ['user_id','book_id', rel_col].\n",
    "    rel_col es la relevancia (binaria o graduada).\n",
    "    \"\"\"\n",
    "    user_ratings = test_df[test_df.user_id == (u+1)]\n",
    "    if user_ratings.empty:\n",
    "        return None\n",
    "\n",
    "    true_rels = {\n",
    "        int(row.book_id)-1: row[rel_col]\n",
    "        for _, row in user_ratings.iterrows()\n",
    "    }\n",
    "\n",
    "    scores = pred_matrix[u]\n",
    "    # Top-K \n",
    "    top_k = np.argsort(scores)[::-1][:K]\n",
    "\n",
    "    dcg = 0.0\n",
    "    for rank, item in enumerate(top_k, start=1):\n",
    "        rel = true_rels.get(item, 0)\n",
    "        dcg += (2**rel - 1) / np.log2(rank + 1)\n",
    "\n",
    "    ideal_rels = sorted(true_rels.values(), reverse=True)[:K]\n",
    "    idcg = sum((2**rel - 1) / np.log2(idx + 1)\n",
    "               for idx, rel in enumerate(ideal_rels, start=1))\n",
    "\n",
    "    return dcg / idcg if idcg > 0 else 0.0\n",
    "\n",
    "def get_ndcg(pred_matrix, test_df, K=5, rel_col='rel'):\n",
    "    \"\"\"\n",
    "    nDCG@K promedio sobre todos los usuarios con al menos una valoración.\n",
    "    \"\"\"\n",
    "    total, count = 0.0, 0\n",
    "    num_users = pred_matrix.shape[0]\n",
    "    for u in range(num_users):\n",
    "        val = get_user_ndcg(u, pred_matrix, test_df, K, rel_col)\n",
    "        if val is not None:\n",
    "            total += val\n",
    "            count += 1\n",
    "    return (total / count) if count > 0 else 0.0\n",
    "\n",
    "test_df['rel'] = (test_df.rating >= 4).astype(int)\n",
    "\n",
    "\n",
    "# nDCG@5\n",
    "ndcg_5 = get_ndcg(pred_matrix, test_df, K=5, rel_col='rel')\n",
    "print(f\"nDCG@5 = {ndcg_5:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7557fe11",
   "metadata": {},
   "source": [
    "## Incluimos un sesgo\n",
    "\n",
    "Como un 4 no significa lo mismo para 2 usuarios diferentes, incluimos sesgo tanto en los usuarios como en los libros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2799ed7",
   "metadata": {},
   "source": [
    "**SGD iterativo** con sesgos, devolviendo mu y las listas de sesgos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa514af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def biased_train(train_df, P, Q, lr, reg_f, reg_b, epochs):\n",
    "    \"\"\"\n",
    "    P, Q y sesgos mu, b_u, b_i usando SGD.\n",
    "    Devuelve mu, b_u, b_i, P, Q actualizados.\n",
    "    \"\"\"\n",
    "    # dimensiones\n",
    "    num_users = int(train_df.user_id.max())\n",
    "    num_items = int(train_df.book_id.max())\n",
    "    \n",
    "    mu  = train_df.rating.mean()\n",
    "    b_u = np.zeros(num_users)\n",
    "    b_i = np.zeros(num_items)\n",
    "    \n",
    "    for _ in range(epochs):\n",
    "        for _, row in train_df.iterrows():\n",
    "            u = int(row.user_id) - 1\n",
    "            i = int(row.book_id) - 1\n",
    "            r = row.rating\n",
    "            \n",
    "            pred = mu + b_u[u] + b_i[i] + P[u].dot(Q[i])\n",
    "            err  = r - pred\n",
    "            \n",
    "            # actualizar sesgos\n",
    "            b_u[u] += lr * (err - reg_b * b_u[u])\n",
    "            b_i[i] += lr * (err - reg_b * b_i[i])\n",
    "            \n",
    "            # actualizar factores\n",
    "            for k in range(P.shape[1]):\n",
    "                p_uk = P[u, k]\n",
    "                q_ik = Q[i, k]\n",
    "                P[u, k] += lr * (err * q_ik - reg_f * p_uk)\n",
    "                Q[i, k] += lr * (err * p_uk - reg_f * q_ik)\n",
    "    \n",
    "    return mu, b_u, b_i, P, Q\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb45afc",
   "metadata": {},
   "source": [
    "#### Matriz de predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb48b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def biased_pred_matrix(mu, b_u, b_i, P, Q, min_r=1.0, max_r=5.0):\n",
    "    \"\"\"\n",
    "    Devuelve pred_matrix de forma (NUM_USERS, NUM_ITEMS) con sesgos.\n",
    "    \"\"\"\n",
    "    base = P.dot(Q.T)                 # (NUM_USERS, NUM_ITEMS)\n",
    "    preds = mu + b_u[:, None] + b_i[None, :] + base\n",
    "    return np.clip(preds, min_r, max_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846c97e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu, b_u, b_i, P, Q = biased_train(\n",
    "    train_df,\n",
    "    P, Q,\n",
    "    lr=0.001,\n",
    "    reg_f=0.1,\n",
    "    reg_b=0.01,\n",
    "    epochs=20\n",
    ")\n",
    "\n",
    "pred_matrix = biased_pred_matrix(mu, b_u, b_i, P, Q, 1.0, 5.0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
