{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52cb0c44",
   "metadata": {},
   "source": [
    "## Comparativa de Modelos\n",
    "\n",
    "| Modelo       | MAE  | RMSE | Precisión | Recall | F1   | nDCG  |\n",
    "|-------------:|-----:|-----:|----------:|-------:|-----:|------:|\n",
    "| **KNN (n=1 000)**      | 0.68 | 0.88 | 0.83       | 0.24   | 0.43 | 0.18  |\n",
    "| **PMF**      | 0.77 | 0.99 | 0.71       | 0.54   | 0.53 | 0.12  |\n",
    "| **BeMF**     | 1.56 | 1.95 | 0.69       | 0.40   | 0.51 | 0.20  |\n",
    "| **PMF + Bias** | 0.68 | 0.86 | 0.93       | 0.98   | 0.96 | 0.96  |\n",
    "\n",
    "- **KNN (sample de 1 000 usuarios/libros):** con pocos datos se mantiene alta precisión (0.83) pero muy bajo recall (0.24).  \n",
    "- **PMF “puro”:** converge rápido en MAE/RMSE, pero su ordenamiento en nDCG (0.12) necesita más iteraciones para afinarse.  \n",
    "- **BeMF (Bernoulli MF):** tras 10 iteraciones alcanza nDCG=0.20, pero requiere muchas más pasadas para converger bien en ranking.  \n",
    "- **PMF + Bias:** corrige sesgos globales, de usuario e ítem, logrando el mejor equilibrio entre regresión y ranking con pocas iteraciones (nDCG=0.96).  \n",
    "\n",
    "**Conclusión:** para conjuntos pequeños y pocas iteraciones, PMF+Bias es la opción más robusta; Bernoulli necesita más ciclos para un ranking competitivo, y KNN exige muestras grandes para mejorar el recall."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
